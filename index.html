<!DOCTYPE html>
<html>

<head>
    <meta charset="utf-8">
    <meta name="description"
        content="MultiPark: Multimodal Parking Transformer with Next-Segment Prediction">
    <meta name="keywords" content="Autonomous parking, Imitation learning, Multimodal Planning">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>MultiPark: Multimodal Parking Transformer with Next-Segment Prediction</title>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-ZYH3N96LN5"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag() { dataLayer.push(arguments); }
        gtag('js', new Date());

        gtag('config', 'G-ZYH3N96LN5');
    </script>

    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

    <link rel="stylesheet" href="./static/css/bulma.min.css">
    <link rel="stylesheet" href="./static/css/slick.css">
    <link rel="stylesheet" href="./static/css/slick-theme.css">
    <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.0/css/all.min.css">
    <link rel="stylesheet" href="./static/css/index.css">
    <link rel="icon" href="./static/images/favicon.svg">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script defer src="./static/js/fontawesome.all.min.js"></script>
    <script src="./static/js/slick.min.js"></script>
    <script src="./static/js/index.js"></script>
</head>

<body>

    <section class="hero">
        <div class="hero-body">
            <div class="container is-max-desktop">
                <div class="columns is-centered">
                    <div class="column has-text-centered">
                        <h1 class="title is-2 publication-title">
<!--                             <span class="gradient-blue-text">MultiPark</span>: Multimodal Parking Transformer with Next-Segment Prediction -->
                                <span style="
                                    background: linear-gradient(90deg, #439cf0, #55bb55);
                                    -webkit-background-clip: text;
                                    -webkit-text-fill-color: transparent;
                                    font-size: 1.2em;">MultiPark</span>: Multimodal Parking Transformer with Next-Segment Prediction
                        </h1>
                        <div class="is-size-5 publication-authors">
                            <span class="author-block">
                                <a href="https://wsakobe.github.io/">Han Zheng</a><sup>1†</sup>,
                            </span>
                            <span class="author-block">
                                <a href="https://scholar.google.com/citations?hl=en&user=LZVx3I0AAAAJ&view_op=list_works&sortby=pubdate">Zikang Zhou</a><sup>2</sup>,
                            </span>
                            <span class="author-block">
                                <a href="https://scholar.google.com/citations?user=pWOUGBMAAAAJ&hl=zh-CN">Guli Zhang</a><sup>2</sup>,
                            </span>
                            <span class="author-block">
                                <a href="https://zhepeiwang.github.io/">Zhepei Wang</a><sup>2</sup>,
                            </span>
                            <span class="author-block">
                                <a href="https://wang-kx.github.io/">Kaixuan Wang</a><sup>2</sup>,
                            </span><br>
                            <span class="author-block">
                                <a href="https://peiliangli.github.io/">Peiliang Li</a><sup>2</sup>,
                            </span>
                            <span class="author-block">
                                <a href="https://scholar.google.com/citations?user=u8Q0_xsAAAAJ&hl=en">Shaojie Shen</a><sup>3</sup>,
                            </span>
                            <span class="author-block">
                                <a href="https://qintong.xyz/">Tong Qin</a><sup>1</sup>*,
                            </span>
                            <span class="author-block">
                                <a href="https://automation.sjtu.edu.cn/YANGMing">Ming Yang</a><sup>1</sup>
                            </span>
                        </div>

                        <div class="is-size-5 publication-authors">
                            <!-- <span class="author-block">Institution Name<br>Conference name and year</span> -->
                            <span class="author-block">
                              <sup>1</sup>Shanghai Jiao Tong University&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
                              <sup>2</sup>Zhuoyu Tech&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
                              <sup>3</sup>Hong Kong University of Science and Technology&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br />
                            </span>
                          </div>
              
                          <div class="is-size-5 publication-authors">
                            *Corresponding Author&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;†Project Lead: hanzheng@sjtu.edu.cn
                          </div>

                        <div class="column has-text-centered">
                            <div class="publication-links">
                                <span class="link-block">
                                    <a href="http://arxiv.org/pdf/2505.23189"
                                        class="external-link button is-normal is-rounded is-dark" target="_blank" rel="noopener noreferrer">
                                        <span class="icon">
                                            <i class="fas fa-file-pdf"></i>
                                        </span>
                                        <span>Arxiv</span>
                                    </a>
                                </span>
                                <!-- <span class="link-block">
                                    <a href="./static/trackvla.pdf"
                                        class="external-link button is-normal is-rounded is-dark" >
                                        <span class="icon">
                                            <i class="fas fa-file-pdf"></i>
                                        </span>
                                        <span>Paper</span>
                                    </a>
                                </span> -->
                                <span class="link-block">
                                    <a href="https://github.com/wsakobe/TrackVLA"
                                        class="external-link button is-normal is-rounded is-dark" target="_blank" rel="noopener noreferrer">
                                        <span class="icon">
                                            <i class="fab fa-github"></i>
                                        </span>
                                        <span>Code & Benchmark</span>
                                    </a>
                                </span>
                                <!-- <span class="link-block">
                                    <a href="https://github.com/wsakobe/EVT-Bench"
                                        class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="fab fa-github"></i> </span>
                                        <span>Benchmark</span>
                                    </a>
                                </span> -->
                                <span class="link-block">
                                    <a href="https://youtu.be/v51U3Nk-SK4?si=foz3zbYD8hLHSybC"
                                        class="external-link button is-normal is-rounded is-dark" target="_blank" rel="noopener noreferrer">
                                        <span class="icon">
                                            <i class="fab fa-youtube"></i>
                                        </span>
                                        <span>Video</span>
                                    </a>
                                </span>
                                <span class="link-block">
                                    <a href="./static/trackvla.bib"
                                        class="external-link button is-normal is-rounded is-dark" target="_blank" rel="noopener noreferrer">
                                        <span class="icon">
                                            <i class="fas fa-quote-left"></i> </span>
                                        <span>BibTex</span>
                                    </a>
                                </span>

                            </div>

                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>


    <!-- Results Carousel--> 
    <section class="hero is-light is-small">
        <div class="hero-body">
            <div class="container">
                <div id="results-carousel" class="carousel results-carousel">
                    <div class="item item-jingyuan">
                        <video poster="" id="jingyuan" autoplay controls muted loop playsinline height="100%">
                            <source src="./static/videos/jingyuan.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="item item-long">
                        <video poster="" id="long" autoplay controls muted loop playsinline height="100%">
                            <source src="./static/videos/long_horizon.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="item item-dog">
                        <video poster="" id="dog" autoplay controls muted loop playsinline height="100%">
                            <source src="./static/videos/dog.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="item item-dark">
                        <video poster="" id="dark" autoplay controls muted loop playsinline height="100%">
                            <source src="./static/videos/dark.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="item item-grass">
                        <video poster="" id="grass" autoplay controls muted loop playsinline height="100%">
                            <source src="./static/videos/grass.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="item item-office">
                        <video poster="" id="office" autoplay controls muted loop playsinline height="100%">
                            <source src="./static/videos/office.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="item item-robust">
                        <video poster="" id="robust" autoplay controls muted loop playsinline height="100%">
                            <source src="./static/videos/robust_tracking.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="item item-pursuit">
                        <video poster="" id="pursuit" autoplay controls muted loop playsinline height="100%">
                            <source src="./static/videos/pursuit.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="item item-evt1">
                        <img src="./static/videos/evt_1.gif" alt="EVT1" id="evt1" style="width: 100%; height: 100%; object-fit: cover;">
                    </div>
                    <div class="item item-evt2">
                        <img src="./static/videos/evt_2.gif" alt="EVT2" id="evt2" style="width: 100%; height: 100%; object-fit: cover;">
                    </div>
                </div>
            </div>
        </div>
    </section>

    
    <section class="section">
        <div class="container is-max-desktop">
            <!-- Abstract. -->
            <div class="columns is-centered has-text-centered">
                <div class="column is-four-fifths">
                    <h2 class="title is-3">Abstract</h2>
                    <div class="content has-text-justified">
                        <p>
                            Parking accurately and safely in highly constrained spaces remains a critical challenge.
                            Unlike structured driving environments, parking requires executing complex maneuvers such as frequent gear shifts and steering saturation.
                            Recent attempts to employ imitation learning (IL) for parking have achieved promising results.  
                            However, existing works ignore the multimodal nature of parking behavior in lane-free open space, failing to derive multiple plausible solutions under the same situation.
                            Notably, IL-based methods encompass inherent causal confusion, so enabling a neural network to generalize across diverse parking scenarios is particularly difficult.
                            To address these challenges, we propose MultiPark, an autoregressive transformer for multimodal parking.
                            To handle paths filled with abrupt turning points, we introduce <strong>a data-efficient next-segment prediction paradigm</strong>, enabling spatial generalization and temporal extrapolation.
                            Furthermore, we design learnable parking queries factorized into gear, longitudinal, and lateral components, <strong>parallelly decoding diverse parking behaviors</strong>.
                            To mitigate causal confusion in IL, our method employs target-centric pose and ego-centric collision as <strong>outcome-oriented loss across all modalities</strong> beyond pure imitation loss.
                            Evaluations of real-world datasets demonstrate that MultiPark achieves <strong>state-of-the-art performance</strong> across various scenarios.
                            We deploy MultiPark on a production vehicle, further confirming our approach’s robustness in real-world parking environments.
                        </p>
                    </div>
                </div>
            </div>

            <!--/ Abstract. -->

            <!-- Paper video. -->
            <div class="columns is-centered has-text-centered">
                <div class="column is-four-fifths">
                    <h2 class="title is-3">Summary Video</h2>
                    <div class="publication-video">
                        <iframe src="https://www.youtube.com/embed/v51U3Nk-SK4?rel=0&amp;showinfo=0" frameborder="0"
                            allow="autoplay; encrypted-media" allowfullscreen></iframe>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <section class="section">
        <div class="container is-max-desktop">
            <div class="columns is-centered has-text-centered">
                <div class="column">
                    <h2 class="title is-3">Motivation</h2>
                    <div class="content has-text-justified">
                        <p>
                            In (a), the parking path involves both forward and backward gears, resulting in 
                            discontinuous segments with <strong><span style="color: #41AB59;">sharp turning points</span></strong>. 
                            In (b), under the same scenario, <strong><span style="color: #41AB59;">different drivers may yield distinct parking solutions</span></strong>. 
                            In (c), the blue path <strong><span style="color: #27632a;">accumulates errors and causes collisions</span></strong>, 
                            but the green path can <strong><span style="color: #27632a;">recover from mistakes occurring in the first segment</span></strong>. 
                        </p>
                        <br>
                        <br>
                        <center>
                            <img src="./static/videos/motivation.jpg" alt="Motivation Image" width="100%">
                        </center>
                    </div>
                </div>
            </div>
            <div class="columns is-centered has-text-centered">
                <div class="column">
                    <h2 class="title is-3">Framework</h2>
                    <div class="content has-text-justified">
                        <p>
                            A BEV encoder first takes inputs and <strong><span style="color: #66cc66;">obtains the scene features as key and value for cross-attention</span></strong>. 
                            Next, a query-based decoder <strong><span style="color: #66cc66;">explores both backward and forward gear</span></strong>, where the endpoint serves as the standpoint in the next segment, thereby <strong><span style="color: #66cc66;">rolling out autoregressively</span></strong> and producing multimodal parking paths. 
                            Finally, we select the optimal path and utilize the predicted waypoints to control the vehicle. 
                        </p>
                        <br>
                        <br>
                        <center>
                            <img src="./static/videos/framework.png" alt="Framework Image" width="100%">
                        </center>
                    </div>
                </div>
            </div>
    </section>

    <section>
        <div class="container is-max-desktop">
            <div class="columns is-centered has-text-centered">
                <div class="column">
                    <h2 class="title is-3">Performance</h2>
                    <div class="content has-text-justified">
                        <strong>
                            We compare MultiPark to <span style="color: #66cc66;">six competitive baselines</span>.
                            Note that all baselines are trained on the same dataset until convergence, and we employ the same encoder network as ours for fair comparison.
                            We report the test set results in the Table.
                            Notably, <span style="color: #66cc66;">MultiPark achieves SOTA closed-loop performance on real-world datasets</span> and consistently outperforms the baselines in all metrics, underscoring its generalization across various scenarios.
                        </strong>
                        <br>
                        <br>
                        <center>
                            <img src="./static/videos/performance.png" alt="Performance Image" width="100%">
                        </center>
                    </div>
                </div>
            </div>
<!--            <div class="columns is-centered has-text-centered">
                <div class="column">
                    <h2 class="title is-3">Comparative Results</h2>
                    <div class="content has-text-justified">
                        <center>
                            <img src="./static/videos/comparative.png" alt="Comparative Results Image" width="100%">
                        </center>
                    </div>
                </div>
            </div> -->
        </div>
    </section>
    
    <section class="section" id="BibTeX">
        <div class="container is-max-desktop content">
            <h2 class="title">BibTeX</h2>
            <pre><code>@article{wang2025trackvla,
    author  = {Wang, Shaoan and Zhang, Jiazhao and Li, Minghan and Liu, Jiahang and Li, Anqi and Wu, Kui and Zhong, Fangwei and Yu, Junzhi and Zhang, Zhizheng and Wang, He},
    title   = {TrackVLA: Embodied Visual Tracking in the Wild},
    journal = {arXiv pre-print},
    year    = {2025},
    url     = {http://arxiv.org/abs/2505.23189}
}</code></pre>
        </div>
    </section>

    <br>
    <center class="is-size-10">
      The website (<a href="https://github.com/wsakobe/TrackVLA-web">source code</a>) design was adapted from <a href="https://nerfies.github.io" class="external-link"><span
                class="dnerf">Nerfies</span></a>.
    </center>
    <br>
</body>

</html>
