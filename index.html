<!DOCTYPE html>
<html>

<head>
    <meta charset="utf-8">
    <meta name="description"
        content="TrackVLA: Embodied Visual Tracking in the Wild">
    <meta name="keywords" content="embodied visual tracking, VLA model">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>TrackVLA: Embodied Visual Tracking in the Wild</title>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-ZYH3N96LN5"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag() { dataLayer.push(arguments); }
        gtag('js', new Date());

        gtag('config', 'G-ZYH3N96LN5');
    </script>

    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

    <link rel="stylesheet" href="./static/css/bulma.min.css">
    <link rel="stylesheet" href="./static/css/slick.css">
    <link rel="stylesheet" href="./static/css/slick-theme.css">
    <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.0/css/all.min.css">
    <link rel="stylesheet" href="./static/css/index.css">
    <link rel="icon" href="./static/images/favicon.svg">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script defer src="./static/js/fontawesome.all.min.js"></script>
    <script src="./static/js/slick.min.js"></script>
    <script src="./static/js/index.js"></script>
</head>

<body>

    <section class="hero">
        <div class="hero-body">
            <div class="container is-max-desktop">
                <div class="columns is-centered">
                    <div class="column has-text-centered">
                        <h1 class="title is-2 publication-title">
                            <span class="gradient-purple-text">MultiPark</span>: Multimodal Parking Transformer with Next-Segment Prediction
                        </h1>
                        <div class="is-size-5 publication-authors">
                            <span class="author-block">
                                <a href="https://wsakobe.github.io/">Han Zheng</a><sup>1†</sup>
                            </span>
                            <span class="author-block">
                                <a href="https://scholar.google.com/citations?hl=en&user=LZVx3I0AAAAJ&view_op=list_works&sortby=pubdate">Zikang Zhou</a><sup>2</sup>
                            </span>
                            <span class="author-block">
                                <a href="https://scholar.google.com/citations?user=pWOUGBMAAAAJ&hl=zh-CN">Guli Zhang</a><sup>2</sup>,
                            </span>
                            <span class="author-block">
                                <a href="https://zhepeiwang.github.io/">Zhepei Wang</a><sup>2</sup>,
                            </span>
                            <span class="author-block">
                                <a href="https://wang-kx.github.io/">Kaixuan Wang</a><sup>2</sup>,
                            </span><br>
                            <span class="author-block">
                                <a href="https://peiliangli.github.io/">Peiliang Li</a><sup>2</sup>,
                            </span>
                            <span class="author-block">
                                <a href="https://scholar.google.com/citations?user=u8Q0_xsAAAAJ&hl=en">Shaojie Shen</a><sup>3</sup>,
                            </span>
                            <span class="author-block">
                                <a href="https://qintong.xyz/">Tong Qin</a><sup>1</sup>*,
                            </span>
                            <span class="author-block">
                                <a href="https://automation.sjtu.edu.cn/YANGMing">Ming Yang</a><sup>1</sup>
                            </span>
                        </div>

                        <div class="is-size-5 publication-authors">
                            <!-- <span class="author-block">Institution Name<br>Conference name and year</span> -->
                            <span class="author-block">
                              <sup>1</sup>Shanghai Jiao Tong University&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
                              <sup>2</sup>Zhuoyu Tech&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
                              <sup>3</sup>Hong Kong University of Science and Technology&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br />
                            </span>
                          </div>
              
                          <div class="is-size-5 publication-authors">
                            *Corresponding Author&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;†Project Lead: hanzheng@sjtu.edu.cn
                          </div>

                        <div class="column has-text-centered">
                            <div class="publication-links">
                                <span class="link-block">
                                    <a href="http://arxiv.org/pdf/2505.23189"
                                        class="external-link button is-normal is-rounded is-dark" target="_blank" rel="noopener noreferrer">
                                        <span class="icon">
                                            <i class="fas fa-file-pdf"></i>
                                        </span>
                                        <span>Arxiv</span>
                                    </a>
                                </span>
                                <!-- <span class="link-block">
                                    <a href="./static/trackvla.pdf"
                                        class="external-link button is-normal is-rounded is-dark" >
                                        <span class="icon">
                                            <i class="fas fa-file-pdf"></i>
                                        </span>
                                        <span>Paper</span>
                                    </a>
                                </span> -->
                                <span class="link-block">
                                    <a href="https://github.com/wsakobe/TrackVLA"
                                        class="external-link button is-normal is-rounded is-dark" target="_blank" rel="noopener noreferrer">
                                        <span class="icon">
                                            <i class="fab fa-github"></i>
                                        </span>
                                        <span>Code & Benchmark</span>
                                    </a>
                                </span>
                                <!-- <span class="link-block">
                                    <a href="https://github.com/wsakobe/EVT-Bench"
                                        class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="fab fa-github"></i> </span>
                                        <span>Benchmark</span>
                                    </a>
                                </span> -->
                                <span class="link-block">
                                    <a href="https://youtu.be/v51U3Nk-SK4?si=foz3zbYD8hLHSybC"
                                        class="external-link button is-normal is-rounded is-dark" target="_blank" rel="noopener noreferrer">
                                        <span class="icon">
                                            <i class="fab fa-youtube"></i>
                                        </span>
                                        <span>Video</span>
                                    </a>
                                </span>
                                <span class="link-block">
                                    <a href="./static/trackvla.bib"
                                        class="external-link button is-normal is-rounded is-dark" target="_blank" rel="noopener noreferrer">
                                        <span class="icon">
                                            <i class="fas fa-quote-left"></i> </span>
                                        <span>BibTex</span>
                                    </a>
                                </span>

                            </div>

                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>


    <!-- Results Carousel--> 
    <section class="hero is-light is-small">
        <div class="hero-body">
            <div class="container">
                <div id="results-carousel" class="carousel results-carousel">
                    <div class="item item-jingyuan">
                        <video poster="" id="jingyuan" autoplay controls muted loop playsinline height="100%">
                            <source src="./static/videos/jingyuan.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="item item-long">
                        <video poster="" id="long" autoplay controls muted loop playsinline height="100%">
                            <source src="./static/videos/long_horizon.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="item item-dog">
                        <video poster="" id="dog" autoplay controls muted loop playsinline height="100%">
                            <source src="./static/videos/dog.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="item item-dark">
                        <video poster="" id="dark" autoplay controls muted loop playsinline height="100%">
                            <source src="./static/videos/dark.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="item item-grass">
                        <video poster="" id="grass" autoplay controls muted loop playsinline height="100%">
                            <source src="./static/videos/grass.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="item item-office">
                        <video poster="" id="office" autoplay controls muted loop playsinline height="100%">
                            <source src="./static/videos/office.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="item item-robust">
                        <video poster="" id="robust" autoplay controls muted loop playsinline height="100%">
                            <source src="./static/videos/robust_tracking.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="item item-pursuit">
                        <video poster="" id="pursuit" autoplay controls muted loop playsinline height="100%">
                            <source src="./static/videos/pursuit.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="item item-evt1">
                        <img src="./static/videos/evt_1.gif" alt="EVT1" id="evt1" style="width: 100%; height: 100%; object-fit: cover;">
                    </div>
                    <div class="item item-evt2">
                        <img src="./static/videos/evt_2.gif" alt="EVT2" id="evt2" style="width: 100%; height: 100%; object-fit: cover;">
                    </div>
                </div>
            </div>
        </div>
    </section>

    
    <section class="section">
        <div class="container is-max-desktop">
            <!-- Abstract. -->
            <div class="columns is-centered has-text-centered">
                <div class="column is-four-fifths">
                    <h2 class="title is-3">Abstract</h2>
                    <div class="content has-text-justified">
                        <p>
                            Parking accurately and safely in highly constrained spaces remains a critical challenge.
Unlike structured driving environments, parking requires executing complex maneuvers such as frequent gear shifts and steering saturation.
Recent attempts to employ imitation learning (IL) for parking have achieved promising results.  
However, existing works ignore the multimodal nature of parking behavior in lane-free open space, failing to derive multiple plausible solutions under the same situation.
Notably, IL-based methods encompass inherent causal confusion, so enabling a neural network to generalize across diverse parking scenarios is particularly difficult.
To address these challenges, we propose MultiPark, an autoregressive transformer for multimodal parking.
To handle paths filled with abrupt turning points, we introduce a data-efficient next-segment prediction paradigm, enabling spatial generalization and temporal extrapolation.
Furthermore, we design learnable parking queries factorized into gear, longitudinal, and lateral components, parallelly decoding diverse parking behaviors.
To mitigate causal confusion in IL, our method employs target-centric pose and ego-centric collision as outcome-oriented loss across all modalities beyond pure imitation loss.
Evaluations of real-world datasets demonstrate that MultiPark achieves state-of-the-art performance across various scenarios.
We deploy MultiPark on a production vehicle, further confirming our approach’s robustness in real-world parking environments.
                        </p>
                    </div>
                </div>
            </div>

            <!--/ Abstract. -->

            <!-- Paper video. -->
            <div class="columns is-centered has-text-centered">
                <div class="column is-four-fifths">
                    <h2 class="title is-3">Summary Video</h2>
                    <div class="publication-video">
                        <iframe src="https://www.youtube.com/embed/v51U3Nk-SK4?rel=0&amp;showinfo=0" frameborder="0"
                            allow="autoplay; encrypted-media" allowfullscreen></iframe>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <section class="section">
        <div class="container is-max-desktop">
            <div class="columns is-centered has-text-centered">
                <div class="column">
                    <h2 class="title is-3">TrackVLA Pipeline</h2>
                    <div class="content has-text-justified">
                        <p>
                            TrackVLA extends video-based VLM/VLA approaches by introducing a parallel prediction branch for both trajectory planning and target recognition.
                            For trajectory planning, TrackVLA organizes online-captured video data, combining historical and current observations, and concatenates them with tracking instructions and a
                            special tracking token. A diffusion transformer then decodes the output tokens from an LLM into waypoints. For recognition tasks, all video frames are encoded identically and processed in a conventional autoregressive manner.
                        </p>
                        <center>
                            <img src="./static/videos/pipeline.png" alt="Pipeline Image" width="80%">
                        </center>
                    </div>
                </div>
            </div>
            <div class="columns is-centered has-text-centered">
                <div class="column">
                    <h2 class="title is-3">Dataset</h2>
                    <div class="content has-text-justified">
                        <p>
                            To train our parallel-branch TrackVLA, we collect a total of 1.7M newly collected samples, including embodied visual tracking and video-based question-answering data.
                        </p>
                        <center>
                            <img src="./static/videos/dataset.png" alt="Pipeline Image" width="80%">
                        </center>
                    </div>
                </div>
            </div>
            <div class="column is-centered has-text-centered">
                <h2 class="title is-3">Long-horizon Tracking</h2>
                <div class="content has-text-justified">
                    <p>
                        TrackVLA is capable of long-horizon tracking in diverse and dynamic environments. It can effectively track targets over long distances while remaining robust against distractors.
                    </p>
                    <!-- <div class="videos-flex"> -->
                    <center>
                        <video poster="" id="indoors-main" autoplay controls muted loop playsinline width="80%">
                            <source src="./static/videos/long_horizon.mp4" type="video/mp4">
                        </video>
                    </center>
                    <!-- </div> -->
                </div>
    </section>


    <section class="section">
        <div class="container is-max-desktop is-centered">
            <center>
                <h2 class="title is-3">Comparison with Commercial Tracking UAV</h2>
            </center>
            <br>
            <div class="content has-text-justified">
                <p>
                    We conducted a series of experiments to compare the tracking performance of TrackVLA with that of a state-of-the-art commercial tracking UAV based on a modular approach. As shown in the video, TrackVLA performs better in challenging scenarios such as target occlusion and fast motion, thanks to its powerful target reasoning capabilities.
                </p>
                <!-- <div class="videos-flex"> -->
                <center>
                    <video poster="" id="go1-inside-2-main" autoplay controls muted loop playsinline width="80%">
                        <source src="./static/videos/comparison.mp4" type="video/mp4">
                    </video>
                </center>
                <!-- </div> -->
            </div>
        </div>
    </section>

    <section class="section">
        <div class="container is-max-desktop is-centered">
            <center>
                <h2 class="title is-3">Environmental Reasoning</h2>
            </center>
            <br>
            <div class="content has-text-justified">
                <p>
                    TrackVLA is capable of reasoning about the environment, enabling it to autonomously recognize traversable areas, avoid obstacles, and generalize to fast-motion and low-illumination scenarios without requiring additional training data.
                </p>
                <!-- <div class="videos-flex" style="display: flex; justify-content: space-between; gap: 1rem; flex-wrap: wrap;">
                    <video poster="" autoplay controls muted loop playsinline style="width: 48%;">
                        <source src="./static/videos/robust_tracking.mp4" type="video/mp4">
                    </video>
                    <video poster="" autoplay controls muted loop playsinline style="width: 48%;">
                        <source src="./static/videos/pursuit.mp4" type="video/mp4">
                    </video>
                    <video poster="" autoplay controls muted loop playsinline style="width: 48%;">
                        <source src="./static/videos/dark.mp4" type="video/mp4">
                    </video>
                </div> -->
            </div>
        </div>
    </section>

    <section class="hero is-light is-small">
        <div class="hero-body">
            <div class="container">
                <div id="results-carousel" class="carousel results-carousel">
                    <div class="item item-robust">
                        <video poster="" id="robust" autoplay controls muted loop playsinline height="100%">
                            <source src="./static/videos/robust_tracking.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="item item-pursuit">
                        <video poster="" id="pursuit" autoplay controls muted loop playsinline height="100%">
                            <source src="./static/videos/pursuit.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="item item-dark">
                        <video poster="" id="dark" autoplay controls muted loop playsinline height="100%">
                            <source src="./static/videos/dark.mp4" type="video/mp4">
                        </video>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <section class="section">
        <div class="container is-max-desktop is-centered">
            <center>
                <h2 class="title is-3">Cross-domain Generalization</h2>
            </center>
            <br>
            <div class="content has-text-justified">
                <p>
                    TrackVLA is capable of cross-domain generalization, enabling robust tracking across diverse scene styles, viewpoints, and camera parameters without additional adaptation.
                </p>
                <!-- <div class="videos-flex"> -->
                <center>
                    <video poster="" id="go1-inside-2-main" autoplay controls muted loop playsinline width="80%">
                        <source src="./static/videos/passive.mp4" type="video/mp4">
                    </video>
                </center>
                <!-- </div> -->
            </div>
        </div>
    </section>

    <section class="section" id="BibTeX">
        <div class="container is-max-desktop content">
            <h2 class="title">BibTeX</h2>
            <pre><code>@article{wang2025trackvla,
    author  = {Wang, Shaoan and Zhang, Jiazhao and Li, Minghan and Liu, Jiahang and Li, Anqi and Wu, Kui and Zhong, Fangwei and Yu, Junzhi and Zhang, Zhizheng and Wang, He},
    title   = {TrackVLA: Embodied Visual Tracking in the Wild},
    journal = {arXiv pre-print},
    year    = {2025},
    url     = {http://arxiv.org/abs/2505.23189}
}</code></pre>
        </div>
    </section>

    <br>
    <center class="is-size-10">
      The website (<a href="https://github.com/wsakobe/TrackVLA-web">source code</a>) design was adapted from <a href="https://nerfies.github.io" class="external-link"><span
                class="dnerf">Nerfies</span></a>.
    </center>
    <br>
</body>

</html>
